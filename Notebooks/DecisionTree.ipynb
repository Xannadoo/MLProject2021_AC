{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = '../Data/df_train.csv'\n",
    "TEST = '../Data/df_test.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_score = lambda x : (x-np.mean(x,axis=0))/ np.std(x,axis=0) #code from exercise 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables and df loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'tab10' #colour theme\n",
    "\n",
    "df = pd.read_csv(TRAIN) #training dataframe\n",
    "\n",
    "attributes = list(df.columns)[:-1] #creates list of column names for later, without the class\n",
    "\n",
    "X = df[attributes].round(3).copy() #attributes\n",
    "df[attributes] = df[attributes].round(3)\n",
    "y = df['type'].copy() #true values\n",
    "df['type_desc'] = ''\n",
    "y_types = {0: 'ERROR', 1:'wind_float', \n",
    "           2:'wind_non', 3:'wind_veh',\n",
    "           4: 'ERROR', 5:'container', \n",
    "           6:'tableware', 7:'headlamp'} #matches catagory name to class number\n",
    "y_list = y.unique() #'y' values\n",
    "\n",
    "X_std = z_score(X) #standardizes X as later we see they are on different scales\n",
    "\n",
    "for i in y_list: #this changes the 'type' to a descriptive word rather than a number\n",
    "    #This is more human readable for plotting later - 'y' is still using the numbers\n",
    "    df['type_desc'][df['type'] == i] = y_types[i]\n",
    "    \n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Gini(g_df, y,threshold):\n",
    "    '''Takes a threshold and calc the Gini impurity of each split of the given df'''\n",
    "    g_df = pd.concat([g_df,y], axis=1,)\n",
    "    g_df.columns=['Att', 'class']\n",
    "    #print(df.head())\n",
    "    \n",
    "    # Initialize an array of zeros to count number of each class in the whole node\n",
    "    class_count = np.zeros((8), dtype=int)\n",
    "    '''for i in range(len(g_df)):\n",
    "        class_count[g_df['class'].iloc[i]]+=1        \n",
    "    class_count = np.delete(class_count, [0,4])'''\n",
    "    \n",
    "    for i in y:\n",
    "        class_count[i] += 1\n",
    "    \n",
    "    #print(class_count)\n",
    "\n",
    "    proportion = [class_count[i]/np.sum(class_count) for i in range(len(class_count))]\n",
    "    #print([round(i,3) for i in proportion])\n",
    "    node_gini = 0\n",
    "    for i in range(len(proportion)):\n",
    "        node_gini += proportion[i]*(1-proportion[i])  \n",
    "    \n",
    "    df_a = g_df[g_df['Att'] <= threshold]\n",
    "    df_b = g_df[g_df['Att'] > threshold]\n",
    "    \n",
    "    n = g_df.shape[0]\n",
    "    n_a = df_a.shape[0]\n",
    "    n_b = df_b.shape[0]\n",
    "    \n",
    "    \n",
    "    #calc and return gini impurity for each side\n",
    "    #print(len(df_a))\n",
    "    #print(len(df_b))\n",
    "    gini_a = 0\n",
    "    gini_b = 0\n",
    "    \n",
    "    for i in y_list: #loop through all classes\n",
    "        \n",
    "        k_a = df_a[df_a['class'] == i] \n",
    "        p_ka = len(k_a)/len(df_a) #count number of class k in first split, divided by total in that split.\n",
    "        \n",
    "        k_b = df_b[df_b['class'] == i]\n",
    "        p_kb = len(k_b)/len(df_b) #count number of class k in first split, divided by total in that split.\n",
    "        \n",
    "        #print(i, k_a,k_b)\n",
    "        \n",
    "        gini_a += (p_ka* (1-p_ka)) #p*(1-p)\n",
    "        gini_b += (p_kb* (1-p_kb)) #p*(1-p)\n",
    "        \n",
    "\n",
    "    #print(round(gini_a, 3), round(gini_b, 3)) #The leaves gini scores are correct!\n",
    "    \n",
    "    return round((n_a/n)*gini_a + (n_b/n)*gini_b, 3), round(node_gini,3), class_count #weighted gini from leaves != overall node gini\n",
    "\n",
    "        \n",
    "        \n",
    "Gini(df['Ba'],y, 0.4) #0.736"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaf_hunter(df):\n",
    "    '''takes df and class returns best weighted leaf gini scores, best threshold, \n",
    "    best attribute and node gini score'''\n",
    "    #So many dratted loops! \n",
    "    best_gini = 1\n",
    "    best_class = ''\n",
    "    best_threshold = 0\n",
    "    best_att = 0\n",
    "    class_cnt = 0\n",
    "    node_gini = 0\n",
    "    if df.shape[0] == 1:\n",
    "        class_count = np.zeros((8), dtype=int)\n",
    "        for i in df['type']:\n",
    "            class_count[i] += 1\n",
    "        return {'best_gini': 0, \n",
    "                'best_threshold': 0, \n",
    "                'best_att': 0, \n",
    "                'node_gini': 0,\n",
    "                'class_count': class_count}\n",
    "    for a in attributes: #loop through attributes\n",
    "        tmp = df.sort_values(by=a, axis=0).copy()\n",
    "        \n",
    "        for threshold in range(len(df)-1): #loop through potential thresholds\n",
    "            \n",
    "            if tmp[a].iloc[threshold] != tmp[a].iloc[threshold+1]: #skip if the two points are the same value\n",
    "                thresh = round((tmp[a].iloc[threshold] + tmp[a].iloc[threshold+1])/2,4)\n",
    "                #print((tmp[a].iloc[threshold], tmp[a].iloc[threshold+1]), thresh)       \n",
    "                gini, node_gini, class_count = Gini(df[a], df['type'], thresh)\n",
    "                \n",
    "                if gini < best_gini:\n",
    "                    best_gini = gini\n",
    "                    best_threshold = thresh\n",
    "                    best_att = a\n",
    "                    class_cnt = class_count\n",
    "                \n",
    "    return {'best_gini': best_gini, \n",
    "            'best_threshold': best_threshold, \n",
    "            'best_att': best_att, \n",
    "            'node_gini': node_gini,\n",
    "            'class_count': class_count}\n",
    "\n",
    "\n",
    "            \n",
    "leaf = leaf_hunter(df)\n",
    "\n",
    "print(leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter([i for i in range(149)], df[leaf[\"best_att\"]], c=y, cmap=col)\n",
    "plt.hlines(leaf[\"best_threshold\"], 0, 149)\n",
    "plt.title(f\"{leaf['best_att']}\");\n",
    "#plt.savefig('../Vis/split 1');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=5)\n",
    "model = clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(model.predict(X)==y)/1.49 #check accuracy of the decision tree at this level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(50,30))\n",
    "_ = tree.plot_tree(model, filled= True)\n",
    "print([(i, attributes[i]) for i in range(len(attributes))]);\n",
    "#plt.savefig('../Vis/sklearn_tree');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.scatter([i for i in range(149)], df['Ba'], c=y, cmap=col)\n",
    "#plt.hlines(0.4, 0, 149)\n",
    "#plt.title('Ba');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_df = df[df[leaf['best_att']] <= leaf[\"best_threshold\"]].copy()\n",
    "b_df = df[df[leaf['best_att']] > leaf[\"best_threshold\"]].copy()\n",
    "print(a_df.shape[0], b_df.shape[0])\n",
    "\n",
    "leaf_a  = leaf_hunter(a_df)\n",
    "\n",
    "print(leaf_a)\n",
    "\n",
    "plt.scatter([i for i in range(a_df.shape[0])], a_df[leaf_a['best_att']], c=a_df['type'], cmap=col)\n",
    "plt.hlines(leaf_a[\"best_threshold\"], 0, a_df.shape[0])\n",
    "plt.title(f'{leaf_a[\"best_att\"]}');\n",
    "#plt.savefig('../Vis/a_split');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_b  = leaf_hunter(b_df)\n",
    "\n",
    "print(leaf_b)\n",
    "\n",
    "plt.scatter([i for i in range(b_df.shape[0])], b_df[leaf_b['best_att']], c=b_df['type'], cmap=col)\n",
    "plt.hlines(leaf_b[\"best_threshold\"], 0, b_df.shape[0])\n",
    "plt.title(f'{leaf_b[\"best_att\"]}');\n",
    "#plt.savefig('../Vis/b_split');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Noodle:\n",
    "    \n",
    "    def __init__(self, df, max_depth=20, print_nodes=False, depth=0):     \n",
    "        tmp = leaf_hunter(df)\n",
    "        self.depth = depth\n",
    "        self.node_gini = tmp['node_gini']\n",
    "        self.best_gini = tmp['best_gini']\n",
    "        self.best_att = tmp['best_att']\n",
    "        self.best_threshold = tmp['best_threshold']\n",
    "        self.class_count = tmp['class_count']\n",
    "        self.no_classes = len(np.nonzero(self.class_count)[0])\n",
    "        self.max_depth = max_depth\n",
    "        self.classification = int(np.where(self.class_count == np.amax(self.class_count))[0][0]) \n",
    "        \n",
    "        if self.no_classes == 1 or self.max_depth < 1:\n",
    "            self.has_children = False\n",
    "        else:\n",
    "            self.has_children = True\n",
    "        \n",
    "        if print_nodes:\n",
    "            print(self)\n",
    "            \n",
    "        if self.depth==0:\n",
    "            with open('../Report/tree.txt', 'w') as f:\n",
    "                f.write(f'{str(self)}')\n",
    "        else:\n",
    "            with open('../Report/tree.txt', 'a') as f:\n",
    "                f.write(f'{str(self)}')\n",
    "                \n",
    "        \n",
    "        \n",
    "        if self.has_children:\n",
    "            a = df[df[self.best_att] <= self.best_threshold]\n",
    "            b = df[df[self.best_att] > self.best_threshold]\n",
    "            self.child_a = Noodle(a, self.max_depth-1, print_nodes, self.depth+1)\n",
    "            self.child_b = Noodle(b, self.max_depth-1, print_nodes, self.depth+1)\n",
    "            \n",
    "            \n",
    "    def __str__ (self):\n",
    "        \n",
    "        peanut = {attributes[i]: i for i in range(len(attributes))}\n",
    "        peanut[0] = ''\n",
    "        \n",
    "        \n",
    "        return(f'Depth: {self.depth}'\n",
    "              + f'\\n{\"  \"*self.depth}Node Gini: {self.node_gini}'\n",
    "              + f'\\n{\"  \"*self.depth}Attribute: {self.best_att} ({peanut[self.best_att]})'\n",
    "              + f'\\n{\"  \"*self.depth}Threshold: {self.best_threshold}'\n",
    "              + f'\\n{\"  \"*self.depth}Classes: {self.class_count}'\n",
    "              + f'\\n{\"  \"*self.depth}No classes: {self.no_classes}'\n",
    "              + f'\\n{\"  \"*self.depth}Node classification: {self.classification}'\n",
    "              + f'\\n{\"  \"*self.depth}Has children: {self.has_children}'\n",
    "              + f'\\n{\"  \"*self.depth}-----------------------\\n')\n",
    "        \n",
    "    def predict(self, test, force_depth=100):\n",
    "        classes = []\n",
    "        for i in range(len(test)):\n",
    "            t = test.iloc[i]\n",
    "            searching = True\n",
    "            sam = bob # makes sam a copy of the decision tree\n",
    "            while searching:\n",
    "                if sam.has_children and sam.depth < force_depth: \n",
    "                    if t[sam.best_att] <= sam.best_threshold:\n",
    "                        sam = sam.child_a\n",
    "                    else:\n",
    "                        sam = sam.child_b\n",
    "                else:\n",
    "                    searching = False\n",
    "                \n",
    "            classes.append(sam.classification)\n",
    "        return classes\n",
    "        \n",
    "bob = Noodle(df)#, print_nodes=True) # This fits the model to the data equiv to .fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ran = 130\n",
    "test = X.iloc[[i for i in range(ran, ran+5)]]\n",
    "pred = bob.predict(test)\n",
    "\n",
    "[i for i in zip(pred, list(df['type'].iloc[[i for i in range(ran, ran+5)]]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "banana = 0 # keeps track of correct classifications\n",
    "df_trained = df.copy()\n",
    "df_trained['classification'] = ''\n",
    "\n",
    "for i in range(len(df)):\n",
    "    test = df.iloc[i]\n",
    "    searching = True\n",
    "    sam = bob # makes sam a copy of the decision tree\n",
    "    while searching:\n",
    "        if sam.has_children and sam.depth < 11: #change depth here for overtraining stuff\n",
    "            if test[sam.best_att] <= sam.best_threshold:\n",
    "                sam = sam.child_a\n",
    "            else:\n",
    "                sam = sam.child_b\n",
    "        else:\n",
    "            searching = False\n",
    "    df_trained['classification'].iloc[i] = sam.classification\n",
    "    if sam.classification == test['type']:\n",
    "        banana +=1\n",
    "    else:\n",
    "        pass\n",
    "        #print('wrong', i, test['type_desc'], sam.classification)\n",
    "        \n",
    "print(f'{round(banana/1.49, 2)}% correct') #should be 100% whilst we are overtraining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trained[df_trained['type'] != df_trained['classification']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5)\n",
    "for train, test in kf.split(X):\n",
    "    print(f\"\\n\\n{len(train)}, {len(test)}\")\n",
    "    #bob = Noodle(pd.DataFrame(df.iloc[train]))\n",
    "    #pred = bob.predict(pd.DataFrame(df.iloc[test]))\n",
    "    #print([i for i in zip(df.iloc[train], pred)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.iloc[30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loads and predicts on the TEST data, run this last once everything else is in place then don't change stuffs\n",
    "#df_test = pd.read_csv(TEST) #training dataframe\n",
    "\n",
    "#X_test = df_test[attributes].round(3).copy() #attributes\n",
    "#df_test[attributes] = df_test[attributes].round(3)\n",
    "#y_test = df_test['type'].copy() #true values\n",
    "\n",
    "#sum([i==j for i,j in zip(bob.predict(X_test), y_test)]), len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
